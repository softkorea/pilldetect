<!DOCTYPE html>
<html lang="ko">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Pill Detection (iOS Final)</title>
    <style>
        body { display: flex; flex-direction: column; align-items: center; font-family: sans-serif; margin: 0; padding: 20px; box-sizing: border-box;}
        
        .container { 
            position: relative; 
            width: 100%; 
            max-width: 640px; 
            /* 화면 비율 유지 */
            min-height: 480px; 
            background: #eee;
            margin-top: 10px;
        }
        
        /* 캔버스는 위에 떠 있어야 함 (z-index: 2) */
        canvas { 
            position: absolute;
            top: 0;
            left: 0;
            width: 100%; 
            height: 100%;
            z-index: 2; 
            object-fit: contain;
        }
        
        /* 비디오는 캔버스 바로 뒤에 실제 크기로 존재해야 함 (z-index: 1) */
        /* opacity: 0으로 설정하면 아이폰이 렌더링을 안 할 수 있어 0.01로 설정 */
        video { 
            position: absolute; 
            top: 0; 
            left: 0; 
            width: 100%; 
            height: 100%;
            z-index: 1;
            opacity: 0.01; 
            object-fit: cover;
        }

        .controls { margin-top: 20px; z-index: 3; position: relative;}
        button { padding: 12px 24px; font-size: 16px; cursor: pointer; border-radius: 8px; border: 1px solid #ccc; background: white;}
        button:disabled { color: #ccc; }
        
        #log { 
            margin-top: 20px; 
            width: 100%; 
            height: 120px; 
            border: 1px solid #333; 
            overflow-y: scroll; 
            font-size: 11px; 
            background: #f9f9f9; 
            padding: 5px;
            font-family: monospace;
        }
    </style>
</head>
<body>

    <h3>Pill Counter (iOS Final)</h3>
    <div id="status">Wait for OpenCV...</div>
    
    <div class="container">
        <video id="videoInput" playsinline webkit-playsinline muted></video>
        <canvas id="canvasOutput"></canvas>
    </div>

    <div class="controls">
        <button id="startBtn" disabled>Start Camera</button>
        <button id="stopBtn" disabled>Stop</button>
    </div>

    <div id="log">Log started...<br></div>

    <script async src="https://docs.opencv.org/4.8.0/opencv.js" onload="onOpenCvReady()" type="text/javascript"></script>

    <script type="text/javascript">
        let video, canvas, ctx;
        let streaming = false;
        let stream = null;
        let cv = null;
        let cap = null;
        let src = null;
        let lastFrameTime = 0;

        function log(msg) {
            const logDiv = document.getElementById('log');
            logDiv.innerHTML += `> ${msg}<br>`;
            logDiv.scrollTop = logDiv.scrollHeight;
            console.log(msg);
        }

        function onOpenCvReady() {
            if (cv && cv.Mat) return;
            cv = window.cv;
            document.getElementById('status').innerText = 'OpenCV Ready';
            log("OpenCV Loaded");
            
            setTimeout(() => {
                initElements();
                document.getElementById('startBtn').disabled = false;
            }, 500);
        }

        function initElements() {
            video = document.getElementById('videoInput');
            canvas = document.getElementById('canvasOutput');
            ctx = canvas.getContext('2d');

            document.getElementById('startBtn').onclick = startCamera;
            document.getElementById('stopBtn').onclick = stopCamera;
        }

        async function startCamera() {
            if (streaming) return;
            log("Requesting Camera...");

            try {
                const constraints = {
                    video: {
                        facingMode: 'environment',
                        width: { ideal: 640 },
                        height: { ideal: 480 }
                    },
                    audio: false
                };

                stream = await navigator.mediaDevices.getUserMedia(constraints);
                video.srcObject = stream;
                
                // 아이폰은 play()가 Promise임
                await video.play();
                
                log(`Video Playing. Size: ${video.videoWidth}x${video.videoHeight}`);

                // 캔버스와 비디오 크기 동기화 (CSS가 아닌 속성값)
                video.width = video.videoWidth;
                video.height = video.videoHeight;
                canvas.width = video.videoWidth;
                canvas.height = video.videoHeight;

                if (cap) { delete cap; cap = null; }
                cap = new cv.VideoCapture(video);
                
                if (src) src.delete();
                src = new cv.Mat(video.videoHeight, video.videoWidth, cv.CV_8UC4);

                streaming = true;
                document.getElementById('startBtn').disabled = true;
                document.getElementById('stopBtn').disabled = false;
                
                log("Starting Process Loop...");
                requestAnimationFrame(processVideo);

            } catch (err) {
                log("Error: " + err.message);
                alert("Error: " + err.message);
            }
        }

        function stopCamera() {
            if (!streaming) return;
            log("Stopping...");

            streaming = false;
            video.pause();
            video.srcObject = null;
            if (stream) {
                stream.getTracks().forEach(track => track.stop());
            }
            
            if (src) { src.delete(); src = null; }
            cap = null;

            document.getElementById('startBtn').disabled = false;
            document.getElementById('stopBtn').disabled = true;
            ctx.clearRect(0, 0, canvas.width, canvas.height);
        }

        function processVideo() {
            if (!streaming) return;

            try {
                // [핵심] 비디오 데이터가 충분하지 않으면 읽지 않고 대기
                if (video.readyState !== 4) { // HAVE_ENOUGH_DATA = 4
                    // 아직 준비 안됨, 다음 프레임 요청
                    requestAnimationFrame(processVideo);
                    return;
                }

                // 리사이징 대응
                if (video.videoWidth !== src.cols || video.videoHeight !== src.rows) {
                    log(`Resize detected: ${video.videoWidth}x${video.videoHeight}`);
                    src.delete();
                    src = new cv.Mat(video.videoHeight, video.videoWidth, cv.CV_8UC4);
                    video.width = video.videoWidth;
                    video.height = video.videoHeight;
                    canvas.width = video.videoWidth;
                    canvas.height = video.videoHeight;
                }

                cap.read(src); // 여기서 에러나면 catch로 이동

                // --- 처리 로직 ---
                let dst = new cv.Mat();
                let count = detectPills(src, dst);

                // 결과 그리기
                cv.imshow('canvasOutput', dst);
                
                // 텍스트 오버레이
                ctx.font = "bold 40px Arial";
                ctx.fillStyle = "red";
                ctx.strokeStyle = "white";
                ctx.lineWidth = 2;
                ctx.strokeText(`Count: ${count}`, 20, 60);
                ctx.fillText(`Count: ${count}`, 20, 60);

                dst.delete();
                // ----------------

                // 첫 프레임 성공 시 로그 (한 번만)
                if (lastFrameTime === 0) {
                    log("First Frame Rendered Success!");
                    lastFrameTime = Date.now();
                }

            } catch (err) {
                // 치명적이지 않은 에러는 로그만 찍고 계속 시도
                console.error(err);
                // log("Loop Err: " + err); // 로그창이 너무 빨라지므로 주석처리
            }

            requestAnimationFrame(processVideo);
        }

        function detectPills(src, dst) {
            let gray = new cv.Mat();
            let blurred = new cv.Mat();
            let binary = new cv.Mat();
            let contours = new cv.MatVector();
            let hierarchy = new cv.MatVector();

            // 1. 전처리 (Gray -> Blur -> Otsu)
            cv.cvtColor(src, gray, cv.COLOR_RGBA2GRAY);
            cv.GaussianBlur(gray, blurred, new cv.Size(5, 5), 0);
            cv.threshold(blurred, binary, 0, 255, cv.THRESH_BINARY_INV + cv.THRESH_OTSU);

            // 2. 형태학적 연산 (노이즈 제거)
            let M = cv.Mat.ones(3, 3, cv.CV_8U);
            cv.morphologyEx(binary, binary, cv.MORPH_OPEN, M);

            // 3. 윤곽선 검출
            cv.findContours(binary, contours, hierarchy, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE);

            // 4. 그리기
            src.copyTo(dst);
            let count = 0;
            const minArea = 1000; // 면적 기준

            for (let i = 0; i < contours.size(); ++i) {
                let contour = contours.get(i);
                let area = cv.contourArea(contour);

                if (area > minArea) {
                    cv.drawContours(dst, contours, i, new cv.Scalar(0, 255, 0, 255), 3, cv.LINE_8, hierarchy, 0);
                    count++;
                }
            }

            // 메모리 정리
            gray.delete(); blurred.delete(); binary.delete();
            contours.delete(); hierarchy.delete(); M.delete();

            return count;
        }
    </script>
</body>
</html>
